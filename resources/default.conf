#@meta {author: 'Paul Landes'}
#@meta {desc: 'application defaults', date: '2024-11-19'}


## Import defaults
#
[import]
#references = list: sdoh_default, default, deeplearn_default, gpu_torch_config
sections = list: sdoh_imp

[sdoh_imp]
config_files = list:
  resource(zensols.mednlp): resources/default.conf,
  resource(zensols.mimic): resources/default.conf,
  resource(zensols.deeplearn): resources/default.conf,
  resource(zensols.deepnlp): resources/default.conf,
  resource(zensols.deepnlp): resources/default.conf


## Application
#
[sdoh_default]
shared_data_dir = ${default:root_dir}/data/share
#label = ${sdoh_default_pre:label}
#model_id = ${sdoh_default_pre:model_id}
#model_name = ${label}-${model_id}
model_name = ${sdoh_default:label}-${sdoh_default:model_id}
embedding = transformer_trainable_embedding
# add trans full last layer: changing this requires rebatch
fulltranout = True
# add description_ features from the medical parser
use_entlink = True
#
cache_lmtask = False


## Overrides
#
[default]
data_dir = ${default:root_dir}/data/${sdoh_default:label}

# deeplearning package defaults
[deeplearn_default]
results_dir = ${default:root_dir}/results/${sdoh_default:label}
batch_dir = ${default:data_dir}/batch/${sdoh_default:model_name}
model_name = ${sdoh_default:model_name}
batch_size = 50


# 16 bit tensors (default is 32)
[gpu_torch_config]
data_type = eval({'import': ['torch']}): torch.bfloat16

# use only local huggingface installed models (set to false for batch phase)
#[deepnlp_default]
#transformer_local_files_only = true


# debugging
# [lmtask_default]
# lmtask_generator = lmtask_constant_generator


## Language model
#
[sdoh_lm_default]
# sdoh_lm_default:feature_hint_type must be set in overrides
data_dir = ${default:data_dir}/${sdoh_lm_default:feature_hint_type}
workers = 1


# train
[lmtask_trainer_default]
source_model = meta-llama/Llama-3.1-8B-Instruct
#checkpoint_dir = ${sdoh_lm_default:data_dir}/sft/model
